{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:00:33.210524Z",
     "start_time": "2019-03-16T17:00:31.805010Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:00:34.451806Z",
     "start_time": "2019-03-16T17:00:34.087205Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121, VGG16, VGG19, InceptionV3, ResNet50, Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:00:38.532481Z",
     "start_time": "2019-03-16T17:00:38.527989Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:00:59.998214Z",
     "start_time": "2019-03-16T17:00:59.990656Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "class_names = ['normal', 'tumor']\n",
    "\n",
    "# h5 weight file\n",
    "weight_file = '../model/diagnosis_tumor_normal.h5'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T17:00:54.990970Z",
     "start_time": "2019-03-16T17:00:42.348389Z"
    }
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights=None, include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T15:48:11.987613Z",
     "start_time": "2019-01-17T15:48:11.889563Z"
    }
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model = multi_gpu_model(model, gpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict at patient level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_id_by_name(full_path):\n",
    "    name = os.path.basename(full_path)\n",
    "    if name.startswith('TCGA'):\n",
    "        return name[:12]\n",
    "    else:\n",
    "        ind = name.find('-')\n",
    "        if ind == -1:\n",
    "            return name[:name.find('_')]\n",
    "        return name[:ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = '../data/diagnosis/kirp'\n",
    "test_dirs = os.path.abspath(test_dirs)  # convert relative path to absolute path\n",
    "mag = '5.0'\n",
    "true_label = 'tumor'\n",
    "result_file = '../result/result_diagnosis_tumor_patient_level.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tile_summary = {}\n",
    "csv_data = {}\n",
    "for class_name in class_names:\n",
    "    tile_summary[class_name] = 0\n",
    "    csv_data[class_name] = []\n",
    "\n",
    "total_patient_count = 0\n",
    "correct_patient_count = 0\n",
    "\n",
    "pids = set([get_id_by_name(full_path) for full_path in glob(test_dirs + '/*')\n",
    "            if full_path.endswith('_files')])\n",
    "\n",
    "for pid in pids:\n",
    "    print('processing ' + pid)\n",
    "    test_paths = glob(test_dirs + '/' + pid + '*/' + mag + '/*jpeg')\n",
    "\n",
    "    if len(test_paths) == 0:\n",
    "        print(pid, \"is empty\")\n",
    "        continue\n",
    "\n",
    "    X_test = np.empty((len(test_paths), 299, 299, 3))\n",
    "\n",
    "    for i, img_path in enumerate(test_paths):\n",
    "        img = image.load_img(img_path)\n",
    "        img = img.resize((299, 299))\n",
    "        X = image.img_to_array(img)\n",
    "        X_test[i, :, :, :] = X / 255\n",
    "\n",
    "    pred_prob = model.predict(X_test)\n",
    "    prob_avg = np.average(pred_prob, 0)\n",
    "\n",
    "    resultMap = {}\n",
    "    resultMap['result type'] = [\"avg prob\", \"count prob\"]\n",
    "    for x in class_names:\n",
    "        resultMap[x] = list()\n",
    "\n",
    "    for i in range(len(class_names)):\n",
    "        resultMap[class_names[i]].append(\"%.4f\" % prob_avg[i])\n",
    "\n",
    "    pred_cls = np.argmax(pred_prob, 1)\n",
    "\n",
    "    for i in range(len(class_names)):\n",
    "        resultMap[class_names[i]].append(\n",
    "            \"%d(%.4f)\" % (np.sum(pred_cls == i), np.sum(pred_cls == i) / len(pred_cls)))\n",
    "        csv_data[class_names[i]].append(round(np.sum(pred_cls == i) / len(pred_cls), 4))\n",
    "    print(pd.DataFrame(resultMap))\n",
    "    #  summary by silde\n",
    "    tile_slide = {}\n",
    "    for i in range(len(class_names)):\n",
    "        cls_count = np.sum(pred_cls == i)\n",
    "        tile_summary[class_names[i]] += cls_count\n",
    "        tile_slide[class_names[i]] = cls_count\n",
    "\n",
    "    tile_slide = dict([(k, tile_slide[k]) for k in class_names])\n",
    "    max_label = max(tile_slide, key=lambda x: tile_slide[x])\n",
    "    correct_patient_count += max_label == true_label\n",
    "    print('predict %s, true_label=%s, predict_label=%s' %\n",
    "          ('success' if max_label == true_label else 'fail', true_label, max_label))\n",
    "    total_patient_count += 1\n",
    "    print()\n",
    "\n",
    "print('----------summary----------')\n",
    "print(\"slide: total:%d, correct:%d, correct_ratio:%.2f\" % (\n",
    "    total_patient_count, correct_patient_count, correct_patient_count / total_patient_count))\n",
    "\n",
    "summary_map = {}\n",
    "for x in class_names:\n",
    "    summary_map[x] = list()\n",
    "\n",
    "for k, v in tile_summary.items():\n",
    "    summary_map[k].append(v)\n",
    "    summary_map[k].append(v / sum(tile_summary.values()))\n",
    "print(pd.DataFrame(summary_map))\n",
    "\n",
    "print('\\nwrite result to %s \\n' % os.path.abspath(result_file))\n",
    "df = pd.DataFrame(csv_data)\n",
    "df.to_csv(result_file, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict at slide level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = '../data/diagnosis/kirp'\n",
    "test_dirs = os.path.abspath(test_dirs)  # convert relative path to absolute path\n",
    "mag = '5.0'\n",
    "true_label = 'tumor'\n",
    "result_file = '../result/result_diagnosis_tumor_slide_level.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_summary = {}\n",
    "csv_data = {}\n",
    "for class_name in class_names:\n",
    "    tile_summary[class_name] = 0\n",
    "    csv_data[class_name] = []\n",
    "\n",
    "total_slide_count = 0\n",
    "correct_slide_count = 0\n",
    "\n",
    "for test_dir in glob(test_dirs + '/*'):\n",
    "    basename = os.path.basename(test_dir)\n",
    "    print(\"processing\", basename)\n",
    "\n",
    "    test_paths = glob(test_dir + '/' + mag + '/*jpeg')\n",
    "    if len(test_paths) == 0:\n",
    "        print(basename, \"is empty\")\n",
    "        continue\n",
    "    \n",
    "    X_test = np.empty((len(test_paths), 299, 299, 3))\n",
    "    \n",
    "    for i, img_path in enumerate(test_paths):\n",
    "        img = image.load_img(img_path)\n",
    "        img = img.resize((299,299))\n",
    "        X = image.img_to_array(img)\n",
    "        X_test[i,:,:,:] = X / 255\n",
    "\n",
    "    pred_prob = model.predict(X_test)\n",
    "    prob_avg = np.average(pred_prob, 0)\n",
    "\n",
    "    resultMap = {}\n",
    "    resultMap['result type']= [\"avg prob\", \"count prob\"]\n",
    "    for x in class_names:\n",
    "        resultMap[x] = list()\n",
    "    \n",
    "    for i in range(len(class_names)):\n",
    "        resultMap[class_names[i]].append(\"%.4f\" % prob_avg[i])\n",
    "        \n",
    "    pred_cls = np.argmax(pred_prob, 1)\n",
    "    \n",
    "    for i in range(len(class_names)):\n",
    "        resultMap[class_names[i]].append(\"%d(%.4f)\" % (np.sum(pred_cls==i), np.sum(pred_cls==i)/len(pred_cls)))\n",
    "        csv_data[class_names[i]].append(round(np.sum(pred_cls == i) / len(pred_cls), 4))\n",
    "    print(pd.DataFrame(resultMap))\n",
    "    \n",
    "    #  summary by silde\n",
    "    tile_slide = {}\n",
    "    for i in range(len(class_names)):\n",
    "        cls_count = np.sum(pred_cls==i)\n",
    "        tile_summary[class_names[i]] += cls_count\n",
    "        tile_slide[class_names[i]] = cls_count\n",
    "    \n",
    "    tile_slide = dict([(k, tile_slide[k]) for k in class_names])\n",
    "    max_label = max(tile_slide, key=lambda x:tile_slide[x])\n",
    "    correct_slide_count += max_label==true_label\n",
    "    print('predict %s, true_label=%s, predict_label=%s' % \n",
    "          ('success' if max_label==true_label else 'fail', true_label, max_label))\n",
    "    total_slide_count += 1\n",
    "    print()\n",
    "\n",
    "print('----------summary----------')\n",
    "print(\"slide: total:%d, correct:%d, correct_ratio:%.2f\" % (\n",
    "      total_slide_count, correct_slide_count, correct_slide_count/total_slide_count))\n",
    "    \n",
    "summary_map = {}\n",
    "for x in class_names:\n",
    "    summary_map[x] = list()    \n",
    "for k, v in tile_summary.items():\n",
    "    summary_map[k].append(v)\n",
    "    summary_map[k].append(v/sum(tile_summary.values()))\n",
    "print(pd.DataFrame(summary_map)) \n",
    "\n",
    "print('\\nwrite result to %s \\n' % os.path.abspath(result_file))\n",
    "df = pd.DataFrame(csv_data)\n",
    "df.to_csv(result_file, index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fucntion used for generating heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T15:48:17.566967Z",
     "start_time": "2019-01-17T15:39:29.689Z"
    }
   },
   "outputs": [],
   "source": [
    "# ['normal', 'tumor']\n",
    "#   gray,     orange\n",
    "colors_list = np.array([[100, 100, 100], [255, 119, 51]])/255\n",
    "colors_rev_list = 1 - colors_list\n",
    "def get_colors(index, prob):\n",
    "    return colors_list[index] + (1-prob)*colors_rev_list[index]\n",
    "\n",
    "def imsave_heapmap_grid(data, filename, block_size=10):\n",
    "    height, width, category = data.shape\n",
    "    assert category <= 5\n",
    "    image_map = np.ones(shape=(height*block_size, width*block_size, 3))\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            probs = data[i][j]\n",
    "            if np.sum(probs) == 0:\n",
    "                continue\n",
    "            c_max = np.argmax(probs)  # class with max probability\n",
    "            c_max_prob = probs[c_max]  # max probability value\n",
    "            color = get_colors(c_max, c_max_prob)\n",
    "            for block_i in range(block_size):\n",
    "                for block_j in range(block_size):\n",
    "                    image_map[i*block_size+block_i][j*block_size+block_j]=color\n",
    "    plt.imsave(filename, image_map)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = '../data/diagnosis/kirp'\n",
    "test_dirs = os.path.abspath(test_dirs)  # convert relative path to absolute path\n",
    "mag = '5.0'\n",
    "heatmap_dir = '../result/heatmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for test_dir in glob(test_dirs + '/*'):\n",
    "    basename = os.path.basename(test_dir)\n",
    "    print(\"processing\", basename)\n",
    "\n",
    "    test_paths = glob(test_dir + '/' + mag + '/*jpeg')\n",
    "    if len(test_paths) == 0:\n",
    "        print(basename, \"is empty\")\n",
    "        continue\n",
    "    \n",
    "    X_test = np.empty((len(test_paths), 299, 299, 3))\n",
    "    \n",
    "    coords = []\n",
    "    for i, img_path in enumerate(test_paths):\n",
    "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        coord = [int(x) for x in name.split(\"_\")[-2:]]\n",
    "        coords.append(coord)\n",
    "        img = image.load_img(img_path)\n",
    "        img = img.resize((299,299))\n",
    "        X = image.img_to_array(img)\n",
    "        X_test[i,:,:,:] = X / 255\n",
    "\n",
    "    pred_prob = model.predict(X_test)\n",
    "\n",
    "    h, w = np.max(coords, 0)+1\n",
    "    prob_map = np.zeros(shape=(h,w,pred_prob.shape[1]))\n",
    "\n",
    "    for i in range(len(coords)):\n",
    "        x, y = coords[i]\n",
    "        prob_map[x][y] = pred_prob[i]\n",
    "    \n",
    "    if not os.path.exists(heatmap_dir):\n",
    "        os.mkdir(heatmap_dir)\n",
    "    imsave_heapmap_grid(prob_map, os.path.join(heatmap_dir, basename  + '_tumor.png'))\n",
    "print(\"\\nheatmaps generated in %s\\n\" % os.path.abspath(heatmap_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save normal list (at patch level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify tumor versus normal at patch level, and output a list of the filenames for predicted normal patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dirs = '../data/diagnosis/kirp'\n",
    "test_dirs = os.path.abspath(test_dirs)  # convert relative path to absolute path\n",
    "normal_list_file = '../result/normal_list.txt'\n",
    "mag = '5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(normal_list_file, \"w\") as file:\n",
    "    for test_dir in glob(test_dirs + '/*'):\n",
    "        basename = os.path.basename(test_dir)\n",
    "\n",
    "        test_paths = glob(test_dir + '/' + mag + '/*jpeg')\n",
    "        if len(test_paths) == 0:\n",
    "            print(basename, \"is empty\")\n",
    "            continue\n",
    "\n",
    "        X_test = np.empty((len(test_paths), 299, 299, 3))\n",
    "\n",
    "        for i, img_path in enumerate(test_paths):\n",
    "            img = image.load_img(img_path)\n",
    "            img = img.resize((299,299))\n",
    "            X = image.img_to_array(img)\n",
    "            X_test[i,:,:,:] = X / 255\n",
    "\n",
    "        # [normal, tumor]\n",
    "        pred_prob = model.predict(X_test)\n",
    "\n",
    "        print(basename)\n",
    "        for i, img_path in enumerate(test_paths):\n",
    "            # if the probability of normal larger than 50%, save the image_path to file\n",
    "            if pred_prob[i][0] > 0.5:\n",
    "                file.write(img_path + '\\n')\n",
    "    print(\"\\nnormal list saved to %s\\n\" % os.path.abspath(normal_list_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "130px",
    "width": "176px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1262px",
    "left": "71px",
    "top": "111.696px",
    "width": "293px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "80"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
